---
title: "Initial Construction of DFs"
author: "Hannah Merges"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning=FALSE, 
                      message=FALSE)
```

## Loading libraries 

```{r, echo=FALSE}
library(lubridate)
library(patchwork)
library(tidyverse)
library(here)
library(car)
library(PNWColors)
library(seacarb)
library(broom)
library(lme4)
library(lmerTest)
library(modelsummary)
library(tidymodels)
library(flextable)
library(performance)
library(agricolae)
library(purrr)
library(nlstools)
library(stringr)
library(emmeans)
library(MuMIn)
```


## Loading the data and creating dfs 
```{r}
RespoMeta <- read_csv(here("Data","RespoFiles","Respo_Metadata2_SGDDilutions_Cabral_Varari.csv")) ##version 2 has deleted Varari_Day3_Col5_Dil1_Light_06212023_O2.csv in it - to make even with RespoR dataframe 

BioData <- read_csv(here("Data","RespoFiles","Fragment_MeasurementSampling_Cabral_Varari2.csv")) ##version 2 has deleted Varari_Day3_Col5_Dil1_Light_06212023_O2.csv in it - to make even with RespoR dataframe 

Sample_Info <- left_join(RespoMeta, BioData)
write_csv(Sample_Info, here::here("Data", "RespoFiles", "Sample_Info.csv"))

pHSlope <- read_csv(here("Data", "pHSlope.csv")) ## also need to delete Varari Col 5 Dil 1 (Light and Dark)
pHSlope <- pHSlope %>% 
  filter(sample_ID!="Varari_Col5_Dil1_Dark", sample_ID!="Varari_Col5_Dil1_Light")

RespoR <- read_csv(here("Data","RespoFiles","Respo_R.csv")) ## saved from a different script

calc_data <- read_csv(here("Data", "Titrations", "Calc_TArates2.csv"))
```

## Compare row names in RespoMeta and BioData to make sure they all overlap before joining in Sample_info 
```{r}
# Step 1: Load the data

# Step 2: Extract row names
row_names1 <- rownames(RespoMeta)
row_names2 <- rownames(BioData)

# Step 3: Compare row names
# Find row names in data1 that are not in data2
non_matching_in_data1 <- setdiff(row_names1, row_names2)

# Find row names in data2 that are not in data1
non_matching_in_data2 <- setdiff(row_names2, row_names1)

# Print the non-matching row names
if (length(non_matching_in_data1) > 0) {
  cat("Row names in data1 not in data2:\n")
  print(non_matching_in_data1)
} else {
  cat("All row names in data1 are present in data2.\n")
}

if (length(non_matching_in_data2) > 0) {
  cat("Row names in data2 not in data1:\n")
  print(non_matching_in_data2)
} else {
  cat("All row names in data2 are present in data1.\n")
}

## All are the same except for last three in BioData which are extra seep samples. Those will get automatically dropped when joining for SampleInfo df 
```


## RespoR2 Table 

```{r}
######################################
#### Respo table ####
######################################

### RespoR is calculated and saved in another script: "Respo_SGDDilutionAssay.R"
### It only has 433 rows, as opposed to 434 from the Sample Info --> which is since edited to remove FiledID_csv "Varari_Day3_Col5_Dil1_Light_06212023_O2.csv" or Sample_ID "Varari_Day3_Col5_Dil1_Light"


######################################################
## join RespoR with Sample Info and tidy 
######################################################

RespoR2 <- RespoR %>%
  #drop_na(FileID_csv) %>% # drop NAs
  left_join(Sample_Info) %>% # Join the raw respo calculations with the metadata in Sample Info 
  #mutate(Ch.Volume.ml = ifelse(is.na(volume_ml),ch.vol,ch.vol-volume_ml)) %>% # add 6 L for volume of all blanks and subtract org volume from chamber vol for all else
  mutate(Ch.Volume.mL = 650-volume_mL) %>% # hannah changed all this volume stuff to match my project
  mutate(Ch.Volume.L = Ch.Volume.mL * 0.001) %>% # mL to L conversion
  mutate(umol.sec = umol.L.sec*Ch.Volume.L) %>% #Account for chamber volume to convert from umol L-1 s-1 to umol s-1. This standardizes across water volumes (different because of coral size) and removes per Liter
  mutate_if(sapply(., is.character), as.factor) %>% #convert character columns to factors
  mutate(new_colonynumber= as.factor(new_colonynumber), 
         date_block= factor(date)) #make the blank column a factor
```

## Normalize to Blanks for regular R and GP and NP respo 
- things to consider here: try both ways 
- 1. average across all the days and get one point for each dilution 
- 2. keep it how it is - grouped by date (i think this is more correct)
```{r}
RespoR_Normalized_blankperday <- RespoR2 %>% 
  group_by(SGD_number, light_dark, date, new_colonynumber, site) %>% 
  filter(new_colonynumber== "BLANK") %>%
  summarise(umol.sec = mean(umol.sec, na.rm=TRUE)) %>% ## so should have one value for each dilution 
  dplyr::select(blank.rate = umol.sec, site)


## two options: 1) summarise across all 4 days 2) direct comparison day to day 
## look at individual blank values to see if any of the days are particularly off - if everything looks consistent, can stick with individual days 
# take out date_block in group by and then change summarise function - to average all blanks by all dilutions 
# go back and check for blank volume to make sure full chamber vol 

###############################################
### plot colonies against blanks ###
###############################################
plot_Blank_Rates <- RespoR_Normalized_blankperday %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(site~date, scales="free_y")

plot_Blank_Rates2 <- RespoR_Normalized_blankperday %>% 
  #filter(date_block!="6/13/23") %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(site~light_dark, scales="free_y")

plot_Blank_Rates2.5 <- RespoR_Normalized_blankperday %>% 
  filter(date!="6/13/23") %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(site~light_dark, scales="free_y")

plot_Blank_Rates3 <- RespoR_Normalized_blankperday %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(date~light_dark, scales="free_y")


##### DELETE 6/13 FROM BLANK DATA FOR CABRAL - JUST SUPER OFF 
RespoR_Normalized_blankperdaynoCabral13th <- RespoR_Normalized_blankperday %>% 
  filter(date!="6/13/23")

```

### Option 2 for Blanks - averaging  
```{r}

RespoR_Normalized_avgblanks <- RespoR2 %>% 
  group_by(SGD_number, light_dark, new_colonynumber, site) %>% 
  filter(new_colonynumber== "BLANK") %>%
  summarise(umol.sec = mean(umol.sec, na.rm=TRUE)) %>% 
## so should have one value for each dilution 
  dplyr::select(blank.rate = umol.sec, site)

### plot the averaged blanks to see if it is working properly ### 
plot_Blank_Rates_Averaged <- RespoR_Normalized_avgblanks %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(site~light_dark)

```

## Now combine into two dfs - one based on per day blank rates and the other based on averaged blank rates 
```{r}
# Check for duplicate sample_IDs in initial and calc_data_post
RespoR2_dups <- RespoR2 %>% 
 group_by(sample_ID) %>% 
 filter(n() > 1)


#joining with per day blanks 
RespoR_Normalized_blankperday_joined_noCabral <- RespoR_Normalized_blankperdaynoCabral13th %>% 
  ungroup() %>% 
  dplyr::select(SGD_number, light_dark, blank.rate, date, site) %>%
  right_join(RespoR2) %>% # join with the respo data
  mutate(umol.sec.corr = umol.sec - blank.rate, # subtract the blank rates from the raw rates
         umol.cm2.hr = (umol.sec.corr*3600)/SA_cm2, # convert to mmol g-1 hr-1
         umol.cm2.hr_uncorr = (umol.sec*3600)/SA_cm2) %>% 
  filter(new_colonynumber!="BLANK") %>% # remove the Blank data
  #ungroup() %>%
  dplyr::select(date, sample_ID, light_dark, SA_cm2, umol.cm2.hr, umol.sec, blank.rate, Temp.C, new_colonynumber, salinity, pH, site, SGD_number, umol.sec.corr, umol.cm2.hr_uncorr, phosphate_umolL, silicate_umolL, NN_umolL, ammonia_umolL) %>%  
  filter(new_colonynumber!=19, new_colonynumber!=20,sample_ID!="Varari_Col5_Dil1_Dark") 
## trying to eliminate the potential for errors here -- so remove the whole colony 5 from Varari (Dark for Respo, Light for GP/NP)


#############################################
# This is WITH Cabral's weird blank data -- DO NOT USE -- SKEWS DATA FOR CABRAL 
#############################################
#RespoR_Normalized_blankperday_joined_withCabral <- RespoR_Normalized_blankperday %>% 
#  ungroup() %>% 
#  dplyr::select(SGD_number, light_dark, blank.rate, date, site) %>%
#  right_join(RespoR2) %>% # join with the respo data
 # mutate(umol.sec.corr = umol.sec - blank.rate, # subtract the blank rates from the raw rates
     #    umol.cm2.hr = (umol.sec.corr*3600)/SA_cm2, # convert to mmol g-1 hr-1
     #    umol.cm2.hr_uncorr = (umol.sec*3600)/SA_cm2) %>% 
 # filter(new_colonynumber!="BLANK") %>% # remove the Blank data
  #ungroup() %>%
#  dplyr::select(date, sample_ID, light_dark, SA_cm2, umol.cm2.hr, umol.sec, blank.rate, Temp.C, new_colonynumber, salinity, pH, site, SGD_number, umol.sec.corr, umol.cm2.hr_uncorr, phosphate_umolL, silicate_umolL, NN_umolL, ammonia_umolL)

```

### Based on what blanks are used -  calculate R, GP, and NP 
- Using blanks per day
- withOUT Cabral (blanks are weird on 13th) and WITH Cabral weird blanks 
Updated on June 3rd 
- going to stick with not using Cabral cols 5/6 (19/20 on new colID) because blanks data is too weird to normalize rates to 

```{r}

###############################
### calculate R 
###############################
# make the respiration values positive (pull out data for dark treatments)

##### Without Cabral 
RespoR_Normalized_dark1 <- RespoR_Normalized_blankperday_joined_noCabral %>% 
  filter(light_dark == "DARK") %>% 
  mutate(umol.cm2.hr = umol.cm2.hr*-1,
         umol.cm2.hr_uncorr = umol.cm2.hr_uncorr*-1) %>% 
  mutate(umol.cm2.hr = ifelse(umol.cm2.hr < 0, 0, umol.cm2.hr),  # for any values below 0, make 0
         umol.cm2.hr_uncorr = ifelse(umol.cm2.hr_uncorr < 0, 0, umol.cm2.hr_uncorr)) %>% 
  mutate(P_R = "R")

# %>% # all dark run rates get R for respiration
 # mutate(umol.cm2.hr = ifelse(umol.cm2.hr ==0, NA, umol.cm2.hr)) ####### DELETE THIS ONCE FIGURE OUT WHAT CABRAL 11/12 

RespoR_Normalized_dark1_dups <- RespoR_Normalized_dark1 %>% 
 group_by(sample_ID) %>% 
  filter(n() > 1)


###############################
### calculate NP 
###############################

##### Without Cabral 
# all light run rates get NP for net photosynthesis
RespoR_Normalized_light <- RespoR_Normalized_blankperday_joined_noCabral %>% 
  filter(light_dark == "LIGHT") %>% 
  mutate(umol.cm2.hr = ifelse(umol.cm2.hr < 0, 0, umol.cm2.hr),  # for any values below 0, make 0
        umol.cm2.hr_uncorr = ifelse(umol.cm2.hr_uncorr < 0, 0, umol.cm2.hr_uncorr)) %>% 
  mutate(P_R = "NP") #%>% 
#  mutate(umol.cm2.hr = ifelse(umol.cm2.hr ==0, NA, umol.cm2.hr)) ####### DELETE THIS ONCE FIGURE OUT WHAT CABRAL 11/12 

# rejoin data into single df
RespoR_Normalized2 <- bind_rows(RespoR_Normalized_light, RespoR_Normalized_dark1) #%>% 
 # drop_na(umol.cm2.hr) # removes C20 and C19 that were weird 

RespoR_Normalized2 <- RespoR_Normalized2 %>% 
  dplyr::select(!c("SA_cm2", "umol.sec", "blank.rate", "umol.sec.corr", "pH"))
  

#make column for GP and group by new_colonynumber, SGD_number, site, date to keep R and NP together
#RespoR_NormalizedGP <- RespoR_Normalized2 %>% 
 # group_by(new_colonynumber, SGD_number, site, date) %>% 
 # summarize(umol.cm2.hr = sum(umol.cm2.hr, na.rm=TRUE), 
         #   umol.cm2.hr_uncorr = sum(umol.cm2.hr_uncorr, na.rm=TRUE)) %>% # NP + R = GP
 # ungroup() %>% 
 # mutate(P_R="GP") %>% # Label for Gross Photosynthesis
 # mutate(light_dark = "LIGHT") %>% 
 # mutate(umol.cm2.hr = ifelse(umol.cm2.hr < 0, 0, umol.cm2.hr), # for any values below 0, make 0
        # umol.cm2.hr_uncorr = ifelse(umol.cm2.hr_uncorr < 0, 0, umol.cm2.hr_uncorr)) 


```

### Figure out how to get nutrient data to copy over into GP columns in R 
from online research 

```{r}
  
RespoR_NormalizedGP_2 <- RespoR_Normalized2 %>%
  group_by(new_colonynumber, SGD_number, site, date) %>%
  summarize(umol.cm2.hr = sum(umol.cm2.hr, na.rm=TRUE),
            umol.cm2.hr_uncorr = sum(umol.cm2.hr_uncorr, na.rm=TRUE)) %>% # NP + R = GP
  ungroup() %>%
  mutate(P_R = "GP", light_dark = "LIGHT") %>% # Label for Gross Photosynthesis
  mutate(umol.cm2.hr = ifelse(umol.cm2.hr < 0, 0, umol.cm2.hr),
         umol.cm2.hr_uncorr = ifelse(umol.cm2.hr_uncorr < 0, 0, umol.cm2.hr_uncorr)) %>%
  left_join(dplyr::select(RespoR_Normalized2, new_colonynumber, sample_ID, SGD_number, site, date, salinity, phosphate_umolL, silicate_umolL, NN_umolL, ammonia_umolL)) 
  
### steps to organize and delete Dark values
RespoR_NormalizedGP_2.1 <- RespoR_NormalizedGP_2 %>% 
  dplyr::mutate(light_dark = str_extract(sample_ID, "[^_]+$"))

RespoR_NormalizedGP_2.1_rows_Dark <- which(RespoR_NormalizedGP_2.1$light_dark == "Dark") #tells you all the rows that you have with blanks
Dark_2 <-RespoR_NormalizedGP_2.1[RespoR_NormalizedGP_2.1_rows_Dark,] 
RespoR_NormalizedGP_2.1_rows_Dark_3 <- RespoR_NormalizedGP_2.1[-RespoR_NormalizedGP_2.1_rows_Dark,] #to remove the rows with dark data, now have data sheet with only light, SA and volume values
RespoR_NormalizedGP_2.1_rows_Dark_3[,8] = NULL #delete the light-dark column to allow to just join by fragment.ID

RespoR_NormalizedGP <- RespoR_NormalizedGP_2.1_rows_Dark_3

###### ^^ This is so that you can join GP data without having to MANUALLY ADD the data!! 

```

### Join into full respo dataset 

```{r}
# rejoin for full df with NP, R, and GP rates
RespoR_Normalized_Full <- RespoR_Normalized2 %>% 
  dplyr::select(new_colonynumber, sample_ID, SGD_number, site, salinity, date, light_dark, P_R, umol.cm2.hr, umol.cm2.hr_uncorr, phosphate_umolL, silicate_umolL, NN_umolL, ammonia_umolL) %>%
  bind_rows(RespoR_NormalizedGP) %>% 
  mutate(umol.cm2.hr = ifelse(umol.cm2.hr ==0, NA, umol.cm2.hr))
 # filter(new_colonynumber!=20)

## what is wrong with Cabral 20? 
#Cabral20 <- RespoR_Normalized_Full %>%
 #filter(site=="Cabral") %>%
 # ggplot(aes(x=SGD_number, 
 #            y=umol.cm2.hr)) + 
 # facet_wrap(~new_colonynumber, scales = "free_y") +
#  geom_point() +
 # geom_smooth(method = "lm", se = FALSE) +
 # scale_x_continuous(trans="log10") 
  #labs(title="Respiration Normalized to Blanks for SGD Dils per colony")

#write_csv(RespoR_Normalized_Full, here::here("Data", "RespoR_Normalized_Full.csv")) ## updated on June 5th 
```



### join Respo rates (RespoR_Normalized_Full) with pH data and SAVE CSV 
```{r}
#Varari_Col5_Dil1 is the problematic one 
################################
### FIRST make sure pH slope csv matches Full Respo Data set up -- all good except for Cabral's whacky colonies which will jsut get filtered out in the joining process 
################################
  
###############################
## now join with Respo Data 
###############################


RespoR_Normalized_Full3 <- RespoR_Normalized_Full %>% 
  left_join(pHSlope, join_by(sample_ID, SGD_number)) ## successfully joined new_pH data --> drops extra 2 Cabral colonies automatically 

RespoR_Normalized_Full3 <- RespoR_Normalized_Full3 %>% 
  select(!c("light_dark", "TrisCalDate"))

#write_csv(RespoR_Normalized_Full3 , here("Data","RespoFiles","RespoR_Normalized_Full3_withpH.csv")) 
### save and then copy and paste nutrients + new_pH into GP rows - May 31st, 2024 

#### manually add nutrient data and re-read
#RespoR_Normalized_Full3 <- read_csv(here::here("Data", "RespoFiles", "RespoR_Normalized_Full3_withpH.csv"))


```

## calculate NEC and save file
Note: May 31st -- NEC data STILL INCLUDES NEW COLONIES 19 and 20 (ie Cabral 11 and 12) -- but not included in Respo Data 
should I add back in ? Or no? NO (June 4th)
```{r}

## deleting re-run to reduce possible duplicates/errors in future joins 
calc_data <- calc_data %>% 
  filter(sample_ID!="Varari_rerunBlankD1_Dil7_Dark", sample_ID!="Varari_rerunBlankD1_Dil7_Light")

#############################################
### create new data frame of just the initial data
### pull out initial data from sample_type
### includes blanks and colonies 
#############################################
initial <- calc_data %>% 
  filter(Sample_Collection == "Initial") %>% #tells you all the rows that you have with initial
  select("date","temp_C", "salinity_insitu", "sample_ID", "SGD_number", "TA", "site", "new_colonynumber") 
## looks good, no errors 

names(initial)[3:6] <- paste0(names(initial)[3:6], "_initial") #use this to rename all of our columns

#############################################
### filter out just the post data
### includes blanks and colonies 
#############################################
post <- calc_data %>% 
  filter(Sample_Collection == "Post") %>% 
  select("date","temp_C", "salinity_insitu", "sample_ID", "SGD_number", "TA", "site", "new_colonynumber") ## no repeats 

##############################
## check for duplicates -- was partially how I solved syntax error 
##############################
# Check for duplicate sample_IDs in initial and calc_data_post
#initial_duplicates <- initial %>% 
 # group_by(sample_ID_initial) %>% 
 # filter(n() > 1)

#calc_data_post_duplicates <- calc_data_post %>% 
 # group_by(sample_ID) %>% 
  #filter(n() > 1)

#calc_data_duplicates <- calc_data %>% 
#  group_by(sample_ID) %>% 
#  filter(n() > 1)

# Verify that there are no duplicate sample_IDs in both dataframes
#initial_duplicates <- initial %>% 
#  group_by(sample_ID_initial) %>% 
#  filter(n() > 1) %>%
#  ungroup()

#calc_data_post_duplicates <- calc_data_post %>% 
 # group_by(sample_ID) %>% 
 # filter(n() > 1) %>%
#  ungroup()

###########################################
## check for white space? 
###########################################

#############################################
## join data 
#############################################

###### join blanks and carb chem data frame
calc_data1 <- post %>% 
  left_join(initial) 
#joining the initials to data frame for carb chem

### JUNE 4th = figured out syntax error that was leading to duplicates and NA data --> was a syntax (copy and paste) error with the temperature and salinity data for Day 1 blanks at Varari. It is resolved now and need to run through the rest of this script! 


#############################################
### remove and create new data frame with just blanks to use for normalizing TA before and after with colonies 
#############################################
blanks_initial <- calc_data %>% 
  filter(Sample_Type == "Blank", 
         Sample_Collection == "Initial")

blanks_post <- calc_data %>% 
  filter(Sample_Type == "Blank", 
         Sample_Collection == "Post")

blanks <- calc_data %>% 
  filter(Sample_Type == "Blank") ## has blanks from both sites 

############################################
## now join initial and blanks back together and use to figure out the change in TA from initial samples and blanks
############################################

blanks1 <- left_join(blanks,initial)

#### figure out delta TA for initial-final for BLANKS ONLY (and then tidy up)
blanks_deltaTA <- blanks1 %>% 
  mutate(delta_TA_blank = TA_initial-TA) %>% 
  select(!c("pH_nonTris", "Sample_Type", "salinity_insitu"))

####### getting the averages of blanks for each date and colony/treatment 
blanks_deltaTA_avg <- blanks_deltaTA %>% 
  select(site, date, SGD_number, delta_TA_blank) %>% 
  filter(delta_TA_blank!=0) %>% 
  group_by(date, site, SGD_number) %>% 
  summarise(mean_blanks=mean(delta_TA_blank))

calc_data_InitalPost_wblanks <- left_join(calc_data1, blanks_deltaTA_avg) #bring in mean blanks to calc_data

############################################
### need to join in SA, volume data and time data by fragment ID, before calculating NEC
############################################
sample_data <- read_csv(here("Data", "RespoFiles", "Fragment_MeasurementSampling_Cabral_Varari.csv")) #bring in SA and volume data sheet

SA <- sample_data[, c("sample_ID", "SA_cm2", "volume_mL")] #pull out the necessary columns and treatment 

SA2 <- SA %>%
 dplyr::mutate(light_dark = str_extract(sample_ID, "[^_]+$")) #split the sample_ID at the underscore to delete the Dark values

### steps to organize and delete D values
rows_Dark <- which(SA2$light_dark == "Dark") #tells you all the rows that you have with blanks
Dark <-SA2[rows_Dark,] 
SA3 <- SA2[-rows_Dark,] #to remove the rows with dark data, now have data sheet with only light, SA and volume values
SA3[,4] = NULL #delete the light-dark column to allow to just join by fragment.ID

SA3 <- SA3 %>% 
  filter(sample_ID!="C0_FGW_061723", sample_ID!="C0_unFGW_060723",  sample_ID!="V0_FGW_061723", sample_ID!="Varari_rerunBlankD1_Dil7_Light") ## get rid of these three rows bc extra from Sample Data sheet, esp Varari so don't fuck up join again!! 

# Check for duplicate sample_IDs 
SA_duplicates <- sample_data %>% 
  group_by(sample_ID) %>% 
 filter(n() > 1)


calc_data_withSA <- calc_data_InitalPost_wblanks %>% 
  left_join(SA3)

############################################
### bring in the time data from resp.data sheet --> RespoMeta
############################################
# Check for duplicate sample_IDs in initial and calc_data_post
Respo_duplicates <- RespoMeta %>% 
  group_by(sample_ID) %>% 
 filter(n() > 1)


######### need to organize and first delete the dark information
rows_dark2 <- which(RespoMeta$light_dark == "DARK") #tells you all the rows that you have with blanks
dark2 <-RespoMeta[rows_dark2 ,] 
resp_data2 <- RespoMeta[-rows_dark2,]

####### pull out columns that we want to use for our bind to the calc.data2 sheet
time_data <- resp_data2 %>% 
  select(c("sample_ID","SGD_dil", "start_time", "stop_time", "site", "date", "light_dark")) %>% 
  filter(sample_ID!="Varari_rerunBlankD1_Dil7_Light")

full_calc_data <- left_join(calc_data_withSA, time_data)

############################################
### NOW calculate the NEC rate
############################################
full_calc_data2 <- full_calc_data %>% 
  mutate(deltaTA = (TA_initial - TA) - mean_blanks) %>%  ### subtract blank data from actual colonies
  mutate(timediff = as.numeric(stop_time - start_time))

##### make a row that has rate.type for "C" assigned to light 
full_calc_data2$P_R <-ifelse(full_calc_data2$light_dark=='LIGHT', "C")

##### equation to calculate NEC rates 
## time is in seconds 

full_calc_data3 <- full_calc_data2 %>% 
  filter(new_colonynumber!="BLANK")

full_calc_data_NEC <- full_calc_data3 %>% 
  mutate(deltaTA_2 = deltaTA/2, 
         deltaTA_L = deltaTA_2*1.025, 
         umol.cm2.s = deltaTA_L*(.650-(volume_mL/1000))/(SA_cm2*timediff), 
         umol.cm2.hr = umol.cm2.s*3600) %>% 
  select(!c(deltaTA_2,deltaTA_L,umol.cm2.s))

write_csv(full_calc_data_NEC , here("Data","full_calc_data_NECrates.csv"))  ### updated on June 5th 
```


## trying to combine NEC data and pH/nut full respo data 
- **NOTE**: Varari_Col1_Dil5_Light is missing from Respo (GP and NP) data as a result of for loop error. Need to delete that in NEC to merge properly 
```{r}
### try to add TA data also 
## using full_calc_NEC which was written and created above ^ 

##############################
## take NEC frame and tidy 
##############################
full_calc_dataNEC_editforjoin <- full_calc_data_NEC %>% 
  select(!c("mean_blanks":"timediff")) %>% 
  filter(new_colonynumber!=19, new_colonynumber!=20, sample_ID!="Varari_Col5_Dil1_Light") 
  
#write_csv(full_calc_dataNEC_editforjoin, here::here("Data", "full_calc_dataNEC_editforjoin.csv"))

##############################
## combine with nutrient data 
##############################

BioData2 <- BioData %>% 
  select(!c("weight_g":"spc", "mV":"mg_L", "pH_night", "TrisCalDate", "CobleA":"Diesel_Chen")) %>% 
  filter(new_colonynumber!="BLANK",new_colonynumber!=19, new_colonynumber!=20, sample_ID!="Varari_Col5_Dil1_Light")

#### extract dark data to continue tidying 
BioData3 <- BioData2 %>%
 dplyr::mutate(light_dark = str_extract(sample_ID, "[^_]+$")) #split the sample_ID at the underscore to delete the Dark values

### steps to organize and delete D values
rows_Dark2 <- which(BioData3$light_dark == "Dark") #tells you all the rows that you have with blanks
Dark2 <-BioData3[rows_Dark,] 
BioData4 <- BioData3[-rows_Dark2,] #to remove the rows with dark data, now have data sheet with only light, SA and volume values
BioData4[,12] = NULL #delete the light-dark column to allow to just join by fragment.ID

#####################################
## now join with nutrients 
#####################################

NEC_wnuts <- full_calc_dataNEC_editforjoin %>% 
  left_join(BioData4)

#####################################
### add in new_pH and temp 
#####################################
### first need to tidy the ph slope df to be able to join properly 

### get rid of Dark values first 
pHSlope_nodark <- pHSlope %>% 
  dplyr::mutate(light_dark = str_extract(sample_ID, "[^_]+$"))

rows_Dark <- which(pHSlope_nodark$light_dark == "Dark") #tells you all the rows that you have with blanks
Dark <-pHSlope_nodark[rows_Dark,] 
pHSlope_nodark <- pHSlope_nodark[-rows_Dark,]

##############################
## now join with NEC and make sure Cabral colonies are deleted then save 
##############################

NEC_wnuts_withpH <- NEC_wnuts %>% 
  left_join(pHSlope_nodark)

write_csv(NEC_wnuts_withpH, here("Data", "NECnuts_withpH.csv"))

```


### join with the Full Respo data of other phsyio measurements (GP, R, NP) 
```{r}
#NEC_wnuts_withpH2 <- NEC_wnuts_withpH %>% 
  #filter(sample_ID!="Varari_Col5_Dil1_Light")

##############################
## now join with Full Respo and save 
##############################
NEC_wnuts_withpH <- NEC_wnuts_withpH %>% 
  select(!c("salinity_insitu_initial", "TA", "sample_ID_initial", "SGD_number_initial","SGD_dil","salinity_insitu", "TrisCalDate", "light_dark"))

RespoR_Normalized_Full_withNEC_nutrients <- RespoR_Normalized_Full3 %>% 
  bind_rows(NEC_wnuts_withpH)

RespoR_Normalized_Full_withNEC_nutrients <- RespoR_Normalized_Full_withNEC_nutrients %>% 
  select(!c("SGD_dil", "umol.cm2.hr_uncorr"))

write_csv(RespoR_Normalized_Full_withNEC_nutrients, here("Data", "RespoR_Normalized_Full_withNEC_andallnutrients.csv")) ### THIS IS ENTIRELY ACCURATE 
## updated and checked EVERYTHING on June 15th - the only thing would potentially need to add manually is TA if want to use that for other measurements for R, NP, and GP 
```



### Problems: (updated June 5th)
- need to check original Respo output -- there is one missing value for Varari Col 5 Dil 1 - Unfortunately from the for loop I believe :/ 
    - current solution: removed it from all the dataframes 
