---
title: "Initial Construction of DFs"
author: "Hannah Merges"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning=FALSE, 
                      message=FALSE)
```

## Loading libraries 

```{r, echo=FALSE}
library(segmented)
library(plotrix)
library(gridExtra)
library(LoLinR)
library(lubridate)
library(chron)
library(patchwork)
library(tidyverse)
library(here)
library(ggrepel)
library(reshape2)
library(viridis)
library(car)
library(GGally)
library(corrplot)
library(PNWColors)
library(seacarb)
library(broom)
library(calecopal)
library(ggridges)
library(lme4)
library(lmerTest)
library(modelsummary)
library(tidymodels)
library(flextable)
library(performance)
library(agricolae)
library(ggeffects)
library(sjPlot)
library(patchwork)
library(broom)
library(purrr)
library(nlstools)
library(stringr)
library(emmeans)
library(MuMIn)
```


## Loading the data and creating dfs 
```{r}
RespoMeta <- read_csv(here("Data","RespoFiles","Respo_Metadata_SGDDilutions_Cabral_Varari.csv"))
BioData <- read_csv(here("Data","RespoFiles","Fragment_MeasurementSampling_Cabral_Varari.csv"))
Sample_Info <- left_join(RespoMeta, BioData)
pHSlope <- read_csv(here("Data", "pHSlope.csv"))
RespoR <- read_csv(here("Data","RespoFiles","Respo_R.csv"))
#full_calc_data <- read_csv(here("Data", "full_calc_data.csv"))
calc_data <- read_csv(here("Data", "Titrations", "Calc_TArates2.csv"))

```

## RespoR2 Table 

```{r}
######### Respo table #############
RespoR2 <- RespoR %>%
  #drop_na(FileID_csv) %>% # drop NAs
  left_join(Sample_Info) %>% # Join the raw respo calculations with the metadata in Sample Info 
  #mutate(Ch.Volume.ml = ifelse(is.na(volume_ml),ch.vol,ch.vol-volume_ml)) %>% # add 6 L for volume of all blanks and subtract org volume from chamber vol for all else
  mutate(Ch.Volume.mL = 650-volume_mL) %>% # hannah changed all this volume stuff to match my project
  mutate(Ch.Volume.L = Ch.Volume.mL * 0.001) %>% # mL to L conversion
  mutate(umol.sec = umol.L.sec*Ch.Volume.L) %>% #Account for chamber volume to convert from umol L-1 s-1 to umol s-1. This standardizes across water volumes (different because of coral size) and removes per Liter
  mutate_if(sapply(., is.character), as.factor) %>% #convert character columns to factors
  mutate(new_colonynumber= as.factor(new_colonynumber), 
         date_block= factor(date)) #make the blank column a factor
```

## Normalize to Blanks for regular R and GP and NP respo 
- things to consider here: try both ways 
- 1. average across all the days and get one point for each dilution 
- 2. keep it how it is - grouped by date (i think this is more correct)
```{r}
RespoR_Normalized_blankperday <- RespoR2 %>% 
  group_by(SGD_number, light_dark, date, new_colonynumber, site) %>% 
  filter(new_colonynumber== "BLANK") %>%
  summarise(umol.sec = mean(umol.sec, na.rm=TRUE)) %>% ## so should have one value for each dilution 
  dplyr::select(blank.rate = umol.sec, site)


## two options: 1) summarise across all 4 days 2) direct comparison day to day 
## look at individual blank values to see if any of the days are particularly off - if everything looks consistent, can stick with individual days 
# take out date_block in group by and then change summarise function - to average all blanks by all dilutions 
# go back and check for blank volume to make sure full chamber vol 

### plot colonies against blanks ######
plot_Blank_Rates <- RespoR_Normalized_blankperday %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(site~date, scales="free_y")

plot_Blank_Rates2 <- RespoR_Normalized_blankperday %>% 
  #filter(date_block!="6/13/23") %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(site~light_dark, scales="free_y")

plot_Blank_Rates2.5 <- RespoR_Normalized_blankperday %>% 
  filter(date!="6/13/23") %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(site~light_dark, scales="free_y")

plot_Blank_Rates3 <- RespoR_Normalized_blankperday %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(date~light_dark, scales="free_y")


##### DELETE 6/13 FROM BLANK DATA FOR CABRAL 
RespoR_Normalized_blankperdaynoCabral13th <- RespoR_Normalized_blankperday %>% 
  filter(date!="6/13/23")

```

### Option 2 for Blanks - averaging  
```{r}

RespoR_Normalized_avgblanks <- RespoR2 %>% 
  group_by(SGD_number, light_dark, new_colonynumber, site) %>% 
  filter(new_colonynumber== "BLANK") %>%
  summarise(umol.sec = mean(umol.sec, na.rm=TRUE)) %>% 
## so should have one value for each dilution 
  dplyr::select(blank.rate = umol.sec, site)

### plot the averaged blanks to see if it is working properly ### 
plot_Blank_Rates_Averaged <- RespoR_Normalized_avgblanks %>% 
  ggplot(aes(x=SGD_number, 
             y=blank.rate)) +
  scale_x_continuous(trans="log10") +
  geom_point() + 
  facet_wrap(site~light_dark)

```

## Now combine into two dfs - one based on per day blank rates and the other based on averaged blank rates 
```{r}
# Check for duplicate sample_IDs in initial and calc_data_post
RespoR2_dups <- RespoR2 %>% 
 group_by(sample_ID) %>% 
 filter(n() > 1)


#joining with per day blanks 
RespoR_Normalized_blankperday_joined_noCabral <- RespoR_Normalized_blankperdaynoCabral13th %>% 
  ungroup() %>% 
  dplyr::select(SGD_number, light_dark, blank.rate, date, site) %>%
  right_join(RespoR2) %>% # join with the respo data
  mutate(umol.sec.corr = umol.sec - blank.rate, # subtract the blank rates from the raw rates
         umol.cm2.hr = (umol.sec.corr*3600)/SA_cm2, # convert to mmol g-1 hr-1
         umol.cm2.hr_uncorr = (umol.sec*3600)/SA_cm2) %>% 
  filter(new_colonynumber!="BLANK") %>% # remove the Blank data
  #ungroup() %>%
  dplyr::select(date, sample_ID, light_dark, SA_cm2, umol.cm2.hr, umol.sec, blank.rate, Temp.C, new_colonynumber, salinity, pH, site, SGD_number, umol.sec.corr, umol.cm2.hr_uncorr, phosphate_umolL, silicate_umolL, NN_umolL, ammonia_umolL) %>%  
  filter(new_colonynumber!=19, new_colonynumber!=20,sample_ID!="Varari_Col5_Dil1_Dark") 
## trying to eliminate the potential for errors here 


#############################################
# This is WITH Cabral's weird blank data -- DO NOT USE -- SKEWS DATA FOR CABRAL 
#############################################
#RespoR_Normalized_blankperday_joined_withCabral <- RespoR_Normalized_blankperday %>% 
#  ungroup() %>% 
#  dplyr::select(SGD_number, light_dark, blank.rate, date, site) %>%
#  right_join(RespoR2) %>% # join with the respo data
 # mutate(umol.sec.corr = umol.sec - blank.rate, # subtract the blank rates from the raw rates
     #    umol.cm2.hr = (umol.sec.corr*3600)/SA_cm2, # convert to mmol g-1 hr-1
     #    umol.cm2.hr_uncorr = (umol.sec*3600)/SA_cm2) %>% 
 # filter(new_colonynumber!="BLANK") %>% # remove the Blank data
  #ungroup() %>%
#  dplyr::select(date, sample_ID, light_dark, SA_cm2, umol.cm2.hr, umol.sec, blank.rate, Temp.C, new_colonynumber, salinity, pH, site, SGD_number, umol.sec.corr, umol.cm2.hr_uncorr, phosphate_umolL, silicate_umolL, NN_umolL, ammonia_umolL)

```

### Based on what blanks are used -  calculate R, GP, and NP 
- Using blanks per day
- withOUT Cabral (blanks are weird on 13th) and WITH Cabral weird blanks 
Updated on June 3rd 
- going to stick with not using Cabral cols 5/6 (19/20 on new colID) because blanks data is too weird to normalize rates to 

```{r}

###############################
### calculate R 
###############################
# make the respiration values positive (pull out data for dark treatments)

##### Without Cabral 
RespoR_Normalized_dark1 <- RespoR_Normalized_blankperday_joined_noCabral %>% 
  filter(light_dark == "DARK") %>% 
  mutate(umol.cm2.hr = umol.cm2.hr*-1,
         umol.cm2.hr_uncorr = umol.cm2.hr_uncorr*-1) %>% 
  mutate(umol.cm2.hr = ifelse(umol.cm2.hr < 0, 0, umol.cm2.hr),  # for any values below 0, make 0
         umol.cm2.hr_uncorr = ifelse(umol.cm2.hr_uncorr < 0, 0, umol.cm2.hr_uncorr)) %>% 
  mutate(P_R = "R")

# %>% # all dark run rates get R for respiration
 # mutate(umol.cm2.hr = ifelse(umol.cm2.hr ==0, NA, umol.cm2.hr)) ####### DELETE THIS ONCE FIGURE OUT WHAT CABRAL 11/12 

RespoR_Normalized_dark1_dups <- RespoR_Normalized_dark1 %>% 
 group_by(sample_ID) %>% 
  filter(n() > 1)


###############################
### calculate NP 
### missing Varari Col 5 Dil 1 LIGHT - from RespoR CSV 
###############################

##### Without Cabral 
# all light run rates get NP for net photosynthesis
RespoR_Normalized_light <- RespoR_Normalized_blankperday_joined_noCabral %>% 
  filter(light_dark == "LIGHT") %>% 
  mutate(umol.cm2.hr = ifelse(umol.cm2.hr < 0, 0, umol.cm2.hr),  # for any values below 0, make 0
        umol.cm2.hr_uncorr = ifelse(umol.cm2.hr_uncorr < 0, 0, umol.cm2.hr_uncorr)) %>% 
  mutate(P_R = "NP") #%>% 
#  mutate(umol.cm2.hr = ifelse(umol.cm2.hr ==0, NA, umol.cm2.hr)) ####### DELETE THIS ONCE FIGURE OUT WHAT CABRAL 11/12 

# rejoin data into single df
RespoR_Normalized2 <- bind_rows(RespoR_Normalized_light, RespoR_Normalized_dark1) #%>% 
 # drop_na(umol.cm2.hr) # removes C20 and C19 that were weird 

RespoR_Normalized2 <- RespoR_Normalized2 %>% 
  select(!c("SA_cm2", "umol.sec", "blank.rate", "umol.sec.corr", "pH"))
  

#make column for GP and group by fragment ID and salinity to keep R and NP together
RespoR_NormalizedGP <- RespoR_Normalized2 %>% 
  group_by(new_colonynumber, SGD_number, site, date) %>% 
  summarize(umol.cm2.hr = sum(umol.cm2.hr, na.rm=TRUE), 
            umol.cm2.hr_uncorr = sum(umol.cm2.hr_uncorr, na.rm=TRUE)) %>% # NP + R = GP
  ungroup() %>% 
  mutate(P_R="GP") %>% # Label for Gross Photosynthesis
  mutate(light_dark = "LIGHT") %>% 
  mutate(umol.cm2.hr = ifelse(umol.cm2.hr < 0, 0, umol.cm2.hr), # for any values below 0, make 0
         umol.cm2.hr_uncorr = ifelse(umol.cm2.hr_uncorr < 0, 0, umol.cm2.hr_uncorr)) 
  

# rejoin for full df with NP, R, and GP rates
RespoR_Normalized_Full <- RespoR_Normalized2 %>% 
  dplyr::select(new_colonynumber, sample_ID, SGD_number, site, salinity, date, light_dark, P_R, umol.cm2.hr, umol.cm2.hr_uncorr, phosphate_umolL, silicate_umolL, NN_umolL, ammonia_umolL) %>%
  bind_rows(RespoR_NormalizedGP) %>% 
  mutate(umol.cm2.hr = ifelse(umol.cm2.hr ==0, NA, umol.cm2.hr))
 # filter(new_colonynumber!=20)

#####################  
####### NEED TO PHYSICALLY COPY THE DATA FROM NP OR R AND PASTE IT VIA MUTATE FOR GP 
#####################  

# Check for duplicate sample_IDs 
RespoR_Normalized_Full_dups <- RespoR_Normalized_Full %>% 
 group_by(sample_ID) %>% 
  filter(n() > 1)

## what is wrong with Cabral 20? 
#Cabral20 <- RespoR_Normalized_Full %>%
 #filter(site=="Cabral") %>%
 # ggplot(aes(x=SGD_number, 
 #            y=umol.cm2.hr)) + 
 # facet_wrap(~new_colonynumber, scales = "free_y") +
#  geom_point() +
 # geom_smooth(method = "lm", se = FALSE) +
 # scale_x_continuous(trans="log10") 
  #labs(title="Respiration Normalized to Blanks for SGD Dils per colony")

#write_csv(RespoR_Normalized_Full, here::here("Data", "RespoR_Normalized_Full.csv")) ## updated on June 5th 

```


### STOPPED HERE FOR LUNCH AND TUTORING: 
- need to either copy over GP data or mess with it in R to see how to get it to join 




### join Respo rates (RespoR_Normalized_Full) with pH data and TA data and SAVE CSV so that can add nutrients after everything else is done
```{r}
Varari_Col5_Dil1_Dark
################################
### FIRST edit pH slope csv to match Full Respo Data set up 
################################
pHSlope <- pHSlope %>%
  filter(sample_ID!="Varari_Col5_Dil1_Dark")
 
  
#dplyr::mutate(light_dark = str_extract(sample_ID, "[^_]+$")) #split the sample_ID at the underscore to delete the Dark values
### steps to organize and delete D values
#rows_Dark_ph <- which(pHSlope_edit$light_dark == "Dark") #tells you all the rows that you have with blanks
#Dark2 <-pHSlope_edit[rows_Dark_ph,] 
#pHSlope_edit2 <- pHSlope_edit[-rows_Dark_ph,] #to remove the rows with dark data, now have data sheet with only light
#SA3[,4] = NULL #delete the light-dark column to allow to just join by fragment.ID


###############################
## now join with Respo Data 
###############################


RespoR_Normalized_Full3 <- RespoR_Normalized_Full %>% 
  left_join(pHSlope, join_by(sample_ID, SGD_number)) ## successfully joined new_pH data --> drops extra 2 Cabral colonies automatically 


#write_csv(RespoR_Normalized_Full3 , here("Data","RespoFiles","RespoR_Normalized_Full3_withpH.csv")) 
### save and then copy and paste nutrients + new_pH into GP rows - May 31st, 2024 

#### manually add nutrient data and re-read
RespoR_Normalized_Full3 <- read_csv(here::here("Data", "RespoFiles", "RespoR_Normalized_Full3_withpH.csv"))


```

## calculate NEC and save file
Note: May 31st -- NEC data STILL INCLUDES NEW COLONIES 19 and 20 (ie Cabral 11 and 12) -- but not included in Respo Data 
should I add back in ? Or no? NO (June 4th)
```{r}

## deleting re-run to reduce possible duplicates/errors in future joins 
calc_data <- calc_data %>% 
  filter(sample_ID!="Varari_rerunBlankD1_Dil7_Dark", sample_ID!="Varari_rerunBlankD1_Dil7_Light")

#############################################
### create new data frame of just the initial data
### pull out initial data from sample_type
### includes blanks and colonies 
#############################################
initial <- calc_data %>% 
  filter(Sample_Collection == "Initial") %>% #tells you all the rows that you have with initial
  select("date","temp_C", "salinity_insitu", "sample_ID", "SGD_number", "TA", "site", "new_colonynumber") 
## looks good, no errors 

names(initial)[3:6] <- paste0(names(initial)[3:6], "_initial") #use this to rename all of our columns

#############################################
### filter out just the post data
### includes blanks and colonies 
#############################################
post <- calc_data %>% 
  filter(Sample_Collection == "Post") %>% 
  select("date","temp_C", "salinity_insitu", "sample_ID", "SGD_number", "TA", "site", "new_colonynumber") ## no repeats 

##############################
## check for duplicates -- was partially how I solved syntax error 
##############################
# Check for duplicate sample_IDs in initial and calc_data_post
#initial_duplicates <- initial %>% 
 # group_by(sample_ID_initial) %>% 
 # filter(n() > 1)

#calc_data_post_duplicates <- calc_data_post %>% 
 # group_by(sample_ID) %>% 
  #filter(n() > 1)

#calc_data_duplicates <- calc_data %>% 
#  group_by(sample_ID) %>% 
#  filter(n() > 1)

# Verify that there are no duplicate sample_IDs in both dataframes
#initial_duplicates <- initial %>% 
#  group_by(sample_ID_initial) %>% 
#  filter(n() > 1) %>%
#  ungroup()

#calc_data_post_duplicates <- calc_data_post %>% 
 # group_by(sample_ID) %>% 
 # filter(n() > 1) %>%
#  ungroup()

###########################################
## check for white space? 
###########################################

#############################################
## join data 
#############################################

###### join blanks and carb chem data frame
calc_data1 <- calc_data_post %>% 
  left_join(initial) 
#joining the initials to data frame for carb chem

### JUNE 4th = figured out syntax error that was leading to duplicates and NA data --> was a syntax (copy and paste) error with the temperature and salinity data for Day 1 blanks at Varari. It is resolved now and need to run through the rest of this script! 


#############################################
### remove and create new data frame with just blanks to use for normalizing TA before and after with colonies 
#############################################
blanks_initial <- calc_data %>% 
  filter(Sample_Type == "Blank", 
         Sample_Collection == "Initial")

blanks_post <- calc_data %>% 
  filter(Sample_Type == "Blank", 
         Sample_Collection == "Post")

blanks <- calc_data %>% 
  filter(Sample_Type == "Blank") ## has blanks from both sites 

############################################
## now join initial and blanks back together and use to figure out the change in TA from initial samples and blanks
############################################

blanks1 <- left_join(blanks,initial)

#### figure out delta TA for initial-final for BLANKS ONLY (and then tidy up)
blanks_deltaTA <- blanks1 %>% 
  mutate(delta_TA_blank = TA_initial-TA) %>% 
  select(!c("pH_nonTris", "Sample_Type", "salinity_insitu"))

####### getting the averages of blanks for each date and colony/treatment 
blanks_deltaTA_avg <- blanks_deltaTA %>% 
  select(site, date, SGD_number, delta_TA_blank) %>% 
  filter(delta_TA_blank!=0) %>% 
  group_by(date, site, SGD_number) %>% 
  summarise(mean_blanks=mean(delta_TA_blank))

calc_data_InitalPost_wblanks <- left_join(calc_data1, blanks_deltaTA_avg) #bring in mean blanks to calc_data

############################################
### need to join in SA, volume data and time data by fragment ID, before calculating NEC
############################################
sample_data <- read_csv(here("Data", "RespoFiles", "Fragment_MeasurementSampling_Cabral_Varari.csv")) #bring in SA and volume data sheet

SA <- sample_data[, c("sample_ID", "SA_cm2", "volume_mL")] #pull out the necessary columns and treatment 

SA2 <- SA %>%
 dplyr::mutate(light_dark = str_extract(sample_ID, "[^_]+$")) #split the sample_ID at the underscore to delete the Dark values

### steps to organize and delete D values
rows_Dark <- which(SA2$light_dark == "Dark") #tells you all the rows that you have with blanks
Dark <-SA2[rows_Dark,] 
SA3 <- SA2[-rows_Dark,] #to remove the rows with dark data, now have data sheet with only light, SA and volume values
SA3[,4] = NULL #delete the light-dark column to allow to just join by fragment.ID

SA3 <- SA3 %>% 
  filter(sample_ID!="C0_FGW_061723", sample_ID!="C0_unFGW_060723",  sample_ID!="V0_FGW_061723", sample_ID!="Varari_rerunBlankD1_Dil7_Light") ## get rid of these three rows bc extra from Sample Data sheet, esp Varari so don't fuck up join again!! 

# Check for duplicate sample_IDs 
SA_duplicates <- sample_data %>% 
  group_by(sample_ID) %>% 
 filter(n() > 1)


calc_data_withSA <- calc_data_InitalPost_wblanks %>% 
  left_join(SA3)

############################################
### bring in the time data from resp.data sheet --> RespoMeta
############################################
# Check for duplicate sample_IDs in initial and calc_data_post
Respo_duplicates <- RespoMeta %>% 
  group_by(sample_ID) %>% 
 filter(n() > 1)


######### need to organize and first delete the dark information
rows_dark2 <- which(RespoMeta$light_dark == "DARK") #tells you all the rows that you have with blanks
dark2 <-RespoMeta[rows_dark2 ,] 
resp_data2 <- RespoMeta[-rows_dark2,]

####### pull out columns that we want to use for our bind to the calc.data2 sheet
time_data <- resp_data2 %>% 
  select(c("sample_ID","SGD_dil", "start_time", "stop_time", "site", "date", "light_dark")) %>% 
  filter(sample_ID!="Varari_rerunBlankD1_Dil7_Light")

full_calc_data <- left_join(calc_data_withSA, time_data)

############################################
### NOW calculate the NEC rate
############################################
full_calc_data2 <- full_calc_data %>% 
  mutate(deltaTA = (TA_initial - TA) - mean_blanks) %>%  ### subtract blank data from actual colonies
  mutate(timediff = as.numeric(stop_time - start_time))

##### make a row that has rate.type for "C" assigned to light 
full_calc_data2$P_R <-ifelse(full_calc_data2$light_dark=='LIGHT', "C")

##### equation to calculate NEC rates 
## time is in seconds 

full_calc_data3 <- full_calc_data2 %>% 
  filter(new_colonynumber!="BLANK")

full_calc_data_NEC <- full_calc_data3 %>% 
  mutate(deltaTA_2 = deltaTA/2, 
         deltaTA_L = deltaTA_2*1.025, 
         umol.cm2.s = deltaTA_L*(.650-(volume_mL/1000))/(SA_cm2*timediff), 
         umol.cm2.hr = umol.cm2.s*3600) %>% 
  select(!c(deltaTA_2,deltaTA_L,umol.cm2.s))

write_csv(full_calc_data_NEC , here("Data","full_calc_data_NECrates.csv"))  ### updated on June 5th 
```


## trying to combine NEC data and pH/nut data 
```{r}
### try to add TA data also 
## using full_calc_NEC which was written and created above ^ 

##############################
## take NEC frame and tidy 
##############################
full_calc_dataNEC_editforjoin <- full_calc_data_NEC %>% 
  select(!c("mean_blanks":"timediff")) %>% 
  filter(new_colonynumber!=19, new_colonynumber!=20) 
  
#write_csv(full_calc_dataNEC_editforjoin, here::here("Data", "full_calc_dataNEC_editforjoin.csv"))

##############################
## combine with nutrient data 
##############################

BioData2 <- BioData %>% 
  select(!c("weight_g":"spc", "mV":"mg_L", "pH_night", "TrisCalDate", "CobleA":"Diesel_Chen")) %>% 
  filter(new_colonynumber!="BLANK",new_colonynumber!=19, new_colonynumber!=20)

#### extract dark data to continue tidying 
BioData3 <- BioData2 %>%
 dplyr::mutate(light_dark = str_extract(sample_ID, "[^_]+$")) #split the sample_ID at the underscore to delete the Dark values

### steps to organize and delete D values
rows_Dark2 <- which(BioData3$light_dark == "Dark") #tells you all the rows that you have with blanks
Dark2 <-BioData3[rows_Dark,] 
BioData4 <- BioData3[-rows_Dark2,] #to remove the rows with dark data, now have data sheet with only light, SA and volume values
BioData4[,12] = NULL #delete the light-dark column to allow to just join by fragment.ID

#####################################
## now join with nutrients 
#####################################

NEC_wnuts <- full_calc_dataNEC_editforjoin %>% 
  left_join(BioData4)

#####################################
### add in new_pH and temp 
#####################################
### first need to tidy the ph slope df to be able to join properly 

### get rid of Dark values first 
pHSlope_nodark <- pHSlope %>% 
  dplyr::mutate(light_dark = str_extract(sample_ID, "[^_]+$"))

rows_Dark <- which(pHSlope_nodark$light_dark == "Dark") #tells you all the rows that you have with blanks
Dark <-pHSlope_nodark[rows_Dark,] 
pHSlope_nodark <- pHSlope_nodark[-rows_Dark,]

##############################
## now join with NEC and make sure Cabral colonies are deleted then save 
##############################

NEC_wnuts_withpH <- NEC_wnuts %>% 
  left_join(pHSlope_nodark)

write_csv(NEC_wnuts_withpH, here("Data", "NECnuts_withpH.csv"))

```

## NOTE: 
- Varari_Col1_Dil5_Light is missing from Respo (GP and NP) data as a result of for loop error. Need to delete that in NEC to merge properly 

### join with the Full Respo data of other phsyio measurements (GP, R, NP) 
```{r}
NEC_wnuts_withpH2 <- NEC_wnuts_withpH %>% 
  filter(sample_ID!="Varari_Col5_Dil1_Light")

##############################
## now join with Full Respo and save 
##############################

RespoR_Normalized_Full3$new_colonynumber <- as.character(RespoR_Normalized_Full3$new_colonynumber)
NEC_wnuts_withpH2$new_colonynumber <- as.character(NEC_wnuts_withpH2$new_colonynumber)


RespoR_Normalized_Full_withNEC <- RespoR_Normalized_Full3 %>% 
  bind_rows(NEC_wnuts_withpH2)

write_csv(RespoR_Normalized_Full_withNEC, here("Data", "RespoR_Normalized_Full_withNEC.csv")) ### THIS IS ACCURATE MINUS GP NUT DATA 
## updated and checked EVERYTHING on June 5th 
```



### Problems: (updated June 5th)
- need to check original Respo output -- there is one missing value for Varari Col 5 Dil 1 - Unfortunately from the for loop I believe :/ 
    - current solution: removed it from all the dataframes 

- Still need to manually copy over GP nutrients if anything changes 

- Full Respo Sheet is wonkyyyy for Varari -- there are less GP values, missing Col 5 and Col 2 for Dil 1 
